# Overview
This project aims to automate the process of subtitling videos. It breaks down the video and leverages AI to transcribe the audio, producing accurate subtitles even when the segments end mid-sentence.

## Workflow
User Video Upload: Users can upload their video for processing.

## Audio Extraction:

The audio is extracted from the video using pydub.
This extraction process converts the audio segment into an mp3 file.
Transcription with Whisper:

The extracted mp3 file is passed to Whisper for transcription.
Whisper returns the transcription of the audio segment.
Timestamp Detection:

A secondary pass is performed on the audio to detect words individually, capturing the timestamps for each word.
## Data Storage:

The transcription data is stored such that users can access it when they log in.
## Punctuation Model:

The transcription is passed through another model to punctuate it correctly.
## Language Translation (Bonus):

There's a potential to introduce translation, converting the transcription from one language to another.
### Considerations
Punctuation: There's an option to exclude punctuation for autogenerated transcriptions.

Fallback Plan: If there's an issue with the subtitling interface, the fallback is to simply use AI for transcription and make it look clean and organized.


## Future Enhancements
Introduction of different language options for a wider audience reach.
Improvement on the overall UI/UX for better user experience.
Contribution & Support
For issues, feature requests, or contributions, kindly refer to the issue tracker or get in touch with the project maintainers.

Remember always to keep keys and sensitive data confidential, and it might be good practice not to include them directly in README files or public repositories. The key is mentioned here only because it was provided in the initial description.